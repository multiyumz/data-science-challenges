{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Houses Kaggle Competition (revisited with Deep Learning üî•) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src='https://wagon-public-datasets.s3.amazonaws.com/data-science-images/ML/kaggle-batch-challenge.png' width=600>](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "‚öôÔ∏è Let's re-use our previous **pipeline** built in the module **`05-07-Ensemble-Methods`** and try to improve our final predictions with a Neural Network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# DATA MANIPULATION\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "\n",
    "# DATA VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# VIEWING OPTIONS IN THE NOTEBOOK\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) üöÄ Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Let's load our **training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
    "X = data.drop(columns='SalePrice')\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ         706          Unf           0        150          856   \n",
       "1          ALQ         978          Unf           0        284         1262   \n",
       "2          GLQ         486          Unf           0        434          920   \n",
       "3          ALQ         216          Unf           0        540          756   \n",
       "4          GLQ         655          Unf           0        490         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
       "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
       "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
       "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
       "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       1710             1             0         2         1             3   \n",
       "1       1262             0             1         2         0             3   \n",
       "2       1786             1             0         2         1             3   \n",
       "3       1717             1             0         1         0             3   \n",
       "4       2198             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2         548         TA   \n",
       "1     Attchd       1976.0          RFn           2         460         TA   \n",
       "2     Attchd       2001.0          RFn           2         608         TA   \n",
       "3     Detchd       1998.0          Unf           3         642         TA   \n",
       "4     Attchd       2000.0          RFn           3         836         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35            272          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  \n",
       "2       WD        Normal  \n",
       "3       WD       Abnorml  \n",
       "4       WD        Normal  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1460,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Let's also load the **test set**\n",
    "\n",
    "‚ùóÔ∏è Remember ‚ùóÔ∏è You have access to `X_test` but only Kaggle has `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Train/Val Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Holdout** ‚ùì \n",
    "\n",
    "As you are not allowed to use the test set (and you don't have access to `y_test` anyway), split your dataset into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 80)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Import the preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ You will find in `utils/preprocessor.py` the **`data-preprocessing pipeline`** that was built in our previous iteration.\n",
    "\n",
    "‚ùì Run the cell below, and make sure you understand what the pipeline does. Look at the code in `preprocessor.py` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;,\n",
       "                                  &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                  &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                  &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                  &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;,\n",
       "                                  &#x27;GrLivArea&#x27;, &#x27;HalfBath...\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;,\n",
       "                                  &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                  &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;,\n",
       "                                  &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                  &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;,\n",
       "                                  &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "                                  &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                  &#x27;Utilities&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;Id&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;HeatingQC&#x27;, &#x27;KitchenQual&#x27;, &#x27;LandContour&#x27;, &#x27;LandSlope&#x27;, &#x27;LotShape&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;No&#x27;, &#x27;Mn&#x27;, &#x27;Av&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Mix&#x27;, &#x27;FuseP&#x27;, &#x27;FuseF&#x27;, &#x27;FuseA&#x27;,\n",
       "                            &#x27;SBrkr&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;...\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;RFn&#x27;, &#x27;Fin&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Low&#x27;, &#x27;Bnk&#x27;, &#x27;HLS&#x27;, &#x27;Lvl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Sev&#x27;, &#x27;Mod&#x27;, &#x27;Gtl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;IR3&#x27;, &#x27;IR2&#x27;, &#x27;IR1&#x27;, &#x27;Reg&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Y&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;]],\n",
       "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;, &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;, &#x27;Utilities&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
       "                 score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x139ee4dc0>))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.preprocessor import create_preproc\n",
    "\n",
    "preproc = create_preproc(X_train)\n",
    "preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Scaling your numerical features and encoding the categorical features** ‚ùì\n",
    "\n",
    "Apply these transformations to _both_ your training set and your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  (&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
       "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
       "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                                   &#x27;BsmtFullBath&#x27;,\n",
       "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                                   &#x27;EnclosedPorch&#x27;,\n",
       "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
       "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
       "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
       "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
       "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
       "                                                   &#x27;MiscFeature&#x27;,\n",
       "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
       "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
       "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                                   &#x27;Utilities&#x27;])])),\n",
       "                (&#x27;selectpercentile&#x27;,\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
       "                                                 (&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;,\n",
       "                                  &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
       "                                  &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
       "                                  &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
       "                                  &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;,\n",
       "                                  &#x27;GrLivArea&#x27;, &#x27;HalfBath...\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;,\n",
       "                                  &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
       "                                  &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;,\n",
       "                                  &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
       "                                  &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;,\n",
       "                                  &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
       "                                  &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
       "                                  &#x27;Utilities&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;Id&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;HeatingQC&#x27;, &#x27;KitchenQual&#x27;, &#x27;LandContour&#x27;, &#x27;LandSlope&#x27;, &#x27;LotShape&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;No&#x27;, &#x27;Mn&#x27;, &#x27;Av&#x27;, &#x27;Gd&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
       "                            &#x27;GLQ&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Mix&#x27;, &#x27;FuseP&#x27;, &#x27;FuseF&#x27;, &#x27;FuseA&#x27;,\n",
       "                            &#x27;SBrkr&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;...\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;RFn&#x27;, &#x27;Fin&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Low&#x27;, &#x27;Bnk&#x27;, &#x27;HLS&#x27;, &#x27;Lvl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Sev&#x27;, &#x27;Mod&#x27;, &#x27;Gtl&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;IR3&#x27;, &#x27;IR2&#x27;, &#x27;IR1&#x27;, &#x27;Reg&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Y&#x27;],\n",
       "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;]],\n",
       "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;, &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;, &#x27;Utilities&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
       "                 score_func=&lt;function mutual_info_regression at 0x139ee4dc0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
       "                                                  Pipeline(steps=[('knnimputer',\n",
       "                                                                   KNNImputer()),\n",
       "                                                                  ('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['1stFlrSF', '2ndFlrSF',\n",
       "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtFullBath',\n",
       "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
       "                                                   'EnclosedPorch',\n",
       "                                                   'Fireplaces', 'FullBath',\n",
       "                                                   'GarageArea', 'GarageCars...\n",
       "                                                   'CentralAir', 'Condition1',\n",
       "                                                   'Condition2', 'Exterior1st',\n",
       "                                                   'Exterior2nd', 'Foundation',\n",
       "                                                   'GarageType', 'Heating',\n",
       "                                                   'HouseStyle', 'LotConfig',\n",
       "                                                   'MSZoning', 'MasVnrType',\n",
       "                                                   'MiscFeature',\n",
       "                                                   'Neighborhood', 'RoofMatl',\n",
       "                                                   'RoofStyle', 'SaleCondition',\n",
       "                                                   'SaleType', 'Street',\n",
       "                                                   'Utilities'])])),\n",
       "                ('selectpercentile',\n",
       "                 SelectPercentile(percentile=75,\n",
       "                                  score_func=<function mutual_info_regression at 0x139ee4dc0>))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preproc = preproc.transform(X_train)\n",
    "X_val_preproc = preproc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.620192</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.344081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424159</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>0.236301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.568309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.563925</td>\n",
       "      <td>0.568523</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657051</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.646246</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.547701</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.057108</td>\n",
       "      <td>0.284247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149140</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600749</td>\n",
       "      <td>0.168028</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276088</td>\n",
       "      <td>0.332688</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.145575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.342239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.133562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191205</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.320025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143746</td>\n",
       "      <td>0.363196</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.268540</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.681537</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066922</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.233936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277125</td>\n",
       "      <td>0.645036</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.491479</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.220316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.050476</td>\n",
       "      <td>0.267123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294455</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.354336</td>\n",
       "      <td>0.214702</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.158258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.362093</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.105481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464653</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.106164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.239551</td>\n",
       "      <td>0.368728</td>\n",
       "      <td>0.376812</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>0.136144</td>\n",
       "      <td>0.352542</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.286726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.328526</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.258406</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.550446</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>0.143836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034417</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.227074</td>\n",
       "      <td>0.042007</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.342087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.381858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440705</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.228006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485244</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.023090</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072658</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.412976</td>\n",
       "      <td>0.224037</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.340014</td>\n",
       "      <td>0.282809</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.431891</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.361124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834592</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035663</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>0.355218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.236757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.424828</td>\n",
       "      <td>0.224037</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows √ó 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1      2         3    4         5    6         7    \\\n",
       "0     0.516240  0.000000  0.375  0.021239  0.0  0.000000  0.0  0.836398   \n",
       "1     0.563925  0.568523  0.500  0.000000  0.0  0.000000  0.0  0.908062   \n",
       "2     0.276088  0.332688  0.500  0.145575  0.0  0.333333  0.0  0.328619   \n",
       "3     0.143746  0.363196  0.375  0.000000  0.0  0.000000  0.0  0.353607   \n",
       "4     0.277125  0.645036  0.500  0.429204  0.0  0.333333  0.0  0.078265   \n",
       "...        ...       ...    ...       ...  ...       ...  ...       ...   \n",
       "1017  0.158258  0.000000  0.250  0.000000  0.0  0.000000  0.0  0.362093   \n",
       "1018  0.136144  0.352542  0.375  0.286726  0.0  0.333333  0.0  0.037718   \n",
       "1019  0.342087  0.000000  0.250  0.381858  0.0  0.333333  0.0  0.217350   \n",
       "1020  0.340014  0.282809  0.500  0.000000  0.0  0.000000  0.0  0.000000   \n",
       "1021  0.355218  0.000000  0.250  0.008850  0.0  0.000000  0.0  0.632720   \n",
       "\n",
       "           8         9         10        11    12        13        14   15   \\\n",
       "0     0.000000  0.333333  0.666667  0.620192  0.75  0.972727  0.344081  0.0   \n",
       "1     0.000000  0.666667  1.000000  0.657051  0.75  0.990909  0.646246  0.5   \n",
       "2     0.000000  0.000000  0.666667  0.192308  0.25  0.227273  0.342239  0.0   \n",
       "3     0.000000  0.000000  0.666667  0.451923  0.50  0.954545  0.268540  0.5   \n",
       "4     0.000000  0.333333  0.666667  0.698718  0.75  0.945455  0.491479  0.5   \n",
       "...        ...       ...       ...       ...   ...       ...       ...  ...   \n",
       "1017  0.217391  0.000000  0.333333  0.192308  0.25  0.218182  0.105481  0.0   \n",
       "1018  0.000000  0.333333  0.666667  0.328526  0.50  0.954545  0.258406  0.5   \n",
       "1019  0.000000  0.333333  0.666667  0.440705  0.50  0.963636  0.228006  0.0   \n",
       "1020  0.000000  0.000000  0.666667  0.431891  0.50  0.709091  0.361124  0.0   \n",
       "1021  0.000000  0.333333  0.666667  0.368590  0.50  0.954545  0.236757  0.0   \n",
       "\n",
       "           16        17        18        19   20        21      22   23   \\\n",
       "0     0.424159  0.333333  0.048583  0.236301  0.0  0.000000  0.2825  0.0   \n",
       "1     0.547701  0.333333  0.057108  0.284247  0.0  0.235294  0.5375  0.0   \n",
       "2     0.341112  0.333333  0.036551  0.133562  0.0  0.176471  0.0000  0.0   \n",
       "3     0.681537  0.333333  0.035271  0.160959  0.0  0.235294  0.0000  0.0   \n",
       "4     0.220316  0.333333  0.050476  0.267123  0.0  0.235294  0.2425  0.0   \n",
       "...        ...       ...       ...       ...  ...       ...     ...  ...   \n",
       "1017  0.464653  0.333333  0.036093  0.106164  0.0  0.058824  0.0000  0.0   \n",
       "1018  0.550446  0.333333  0.032247  0.143836  0.0  0.235294  0.0000  0.0   \n",
       "1019  0.485244  0.333333  0.023090  0.092466  0.0  0.588235  0.1100  0.0   \n",
       "1020  0.834592  0.666667  0.035663  0.160959  0.0  0.411765  0.0000  0.0   \n",
       "1021  0.472889  0.333333  0.029339  0.136986  0.0  0.588235  0.1600  0.0   \n",
       "\n",
       "           24     25        26        27        28        29        30   \\\n",
       "0     0.206501  0.500  0.888889  0.590909  0.583333  0.568309  0.000000   \n",
       "1     0.149140  0.500  0.888889  0.000000  0.750000  0.600749  0.168028   \n",
       "2     0.191205  0.625  0.666667  0.000000  0.500000  0.320025  0.000000   \n",
       "3     0.066922  0.500  0.555556  0.000000  0.333333  0.233936  0.000000   \n",
       "4     0.294455  0.500  0.777778  0.000000  0.666667  0.354336  0.214702   \n",
       "...        ...    ...       ...       ...       ...       ...       ...   \n",
       "1017  0.000000  0.875  0.444444  0.000000  0.250000  0.239551  0.368728   \n",
       "1018  0.034417  0.500  0.666667  0.000000  0.416667  0.227074  0.042007   \n",
       "1019  0.072658  0.500  0.777778  0.000000  0.333333  0.412976  0.224037   \n",
       "1020  0.000000  0.500  0.555556  0.000000  0.500000  0.000000  0.000000   \n",
       "1021  0.053537  0.500  0.555556  0.000000  0.333333  0.424828  0.224037   \n",
       "\n",
       "           31        32    33    34        35        36    37   38        39   \\\n",
       "0     0.978261  0.950000  0.75  0.75  1.000000  0.166667  1.00  1.0  0.333333   \n",
       "1     0.985507  0.983333  0.75  0.25  0.166667  0.166667  1.00  1.0  0.333333   \n",
       "2     0.384058  0.000000  0.75  0.25  0.500000  0.166667  0.50  1.0  0.666667   \n",
       "3     0.963768  0.933333  0.75  0.25  0.166667  0.166667  0.75  1.0  0.333333   \n",
       "4     0.956522  0.900000  0.75  0.75  1.000000  0.166667  1.00  1.0  0.333333   \n",
       "...        ...       ...   ...   ...       ...       ...   ...  ...       ...   \n",
       "1017  0.376812  0.933333  0.75  0.25  0.166667  0.166667  0.50  1.0  0.333333   \n",
       "1018  0.963768  0.916667  0.75  0.75  1.000000  0.166667  0.75  1.0  0.333333   \n",
       "1019  0.971014  0.933333  0.75  0.25  1.000000  0.166667  0.75  1.0  0.333333   \n",
       "1020  0.768116  0.466667  0.00  0.00  0.000000  0.000000  0.00  1.0  0.333333   \n",
       "1021  0.963768  0.933333  0.75  0.75  0.833333  0.166667  0.75  1.0  0.333333   \n",
       "\n",
       "           40   41   42   43   44        45   46   47        48   49   \\\n",
       "0     1.000000  0.0  0.8  1.0  0.6  0.333333  0.6  1.0  0.666667  1.0   \n",
       "1     1.000000  0.0  0.8  1.0  0.6  1.000000  0.6  1.0  1.000000  1.0   \n",
       "2     0.333333  1.0  0.0  1.0  0.6  0.333333  0.6  1.0  0.333333  1.0   \n",
       "3     0.333333  0.0  0.0  1.0  0.6  0.666667  0.6  1.0  0.666667  1.0   \n",
       "4     0.666667  0.0  0.8  1.0  0.6  1.000000  0.6  1.0  0.666667  1.0   \n",
       "...        ...  ...  ...  ...  ...       ...  ...  ...       ...  ...   \n",
       "1017  0.666667  0.0  0.0  1.0  0.4  0.333333  0.4  1.0  0.666667  1.0   \n",
       "1018  0.666667  0.0  0.8  1.0  0.6  1.000000  0.6  1.0  0.666667  1.0   \n",
       "1019  0.666667  0.0  0.8  1.0  0.6  1.000000  0.6  1.0  0.666667  1.0   \n",
       "1020  0.333333  0.0  0.0  1.0  0.6  0.333333  0.6  0.5  0.333333  1.0   \n",
       "1021  0.666667  0.0  0.8  1.0  0.6  0.666667  0.6  1.0  0.666667  1.0   \n",
       "\n",
       "           50   51   52   53   54   55   56   57   58   59   60   61   62   \\\n",
       "0     1.000000  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     1.000000  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2     1.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "3     1.000000  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "4     0.666667  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  1.000000  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1018  1.000000  1.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1019  1.000000  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1020  1.000000  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1021  0.666667  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      63   64   65   66   67   68   69   70   71   72   73   74   75   76   \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1018  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1019  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1020  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1021  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      77   78   79   80   81   82   83   84   85   86   87   88   89   90   \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "4     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "1018  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1019  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1020  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "1021  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      91   92   93   94   95   96   97   98   99   100  101  102  103  104  \\\n",
       "0     1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1     1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "3     1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1018  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1019  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1020  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1021  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "\n",
       "      105  106  107  108  109  110  111  112  113  114  115  116  117  118  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "4     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1018  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "1019  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
       "1020  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
       "1021  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "      119  120  121  122  123  124  125  126  127  128  129  130  131  132  \\\n",
       "0     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1018  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1019  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1020  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1021  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      133  134  135  136  137  138  139  140  141  142  143  144  145  146  \\\n",
       "0     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1017  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1018  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1019  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1020  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1021  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      147  148  149  150  151  152  153  154  155  156  157  158  159  \n",
       "0     0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "2     1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "3     1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
       "4     1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1017  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1018  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1019  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1020  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "1021  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  \n",
       "\n",
       "[1022 rows x 160 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preproc = preproc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) üîÆ Your predictions in Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ This is your first **regression** task with Keras! \n",
    "\n",
    "üí° Here a few tips to get started:\n",
    "- Kaggle's [rule](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) requires to minimize **`rmsle`** (Root Mean Square Log Error). \n",
    "    - As you can see, we can specify `msle` directly as a loss-function with Tensorflow.Keras!\n",
    "    - Just remember to take the square-root of your loss results to read your rmsle metric.\n",
    "    \n",
    "    \n",
    "üòÉ The best boosted-tree ***rmsle*** score to beat is around ***0.13***\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://i.pinimg.com/564x/4c/fe/ef/4cfeef34af09973211f584e8307b433c.jpg\" alt=\"`Impossible mission\" style=\"height: 300px; width:500px;\"/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "‚ùì **Your mission, should you choose to accept it:** ‚ùì\n",
    "- üí™ Beat the best boosted-tree üí™ \n",
    "\n",
    "    - Your responsibilities are:\n",
    "        - to build the ***best neural network architecture*** possible,\n",
    "        - and to control the number of epochs to ***avoid overfitting***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Predicting the houses' prices using a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Preliminary Question: Initializing a Neural Network** ‚ùì\n",
    "\n",
    "Create a function `initialize_model` which initializes a Dense Neural network:\n",
    "- You are responsible for designing the architecture (number of layers, number of neurons)\n",
    "- The function should also compile the model with the following parameters:\n",
    "    - ***optimizer = \"adam\"***\n",
    "    - ***loss = \"msle\"*** (_Optimizing directly for the Squared Log Error!_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_model(X):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(20, activation='relu', input_dim=X.shape[-1]))\n",
    "    \n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='msle')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions/Guidance** ‚ùì\n",
    "\n",
    "1. Initialize a Neural Network\n",
    "2. Train it\n",
    "3. Evaluate its performance\n",
    "4. Is the model overfitting the dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 20)                3220      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 15)                315       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 15)                240       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                320       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,116\n",
      "Trainable params: 4,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = initialize_model(X_train_preproc)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "64/64 [==============================] - 1s 6ms/step - loss: 117.4942 - val_loss: 92.9051\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 75.4643 - val_loss: 60.7310\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 51.5772 - val_loss: 43.3052\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 37.5148 - val_loss: 32.2632\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 28.6222 - val_loss: 25.1891\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 22.6962 - val_loss: 20.2666\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 18.4602 - val_loss: 16.6482\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 15.2174 - val_loss: 13.6280\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 12.3716 - val_loss: 11.0929\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 10.1523 - val_loss: 9.1697\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.4452 - val_loss: 7.6698\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.0973 - val_loss: 6.4692\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.0098 - val_loss: 5.4937\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.1188 - val_loss: 4.6874\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.3792 - val_loss: 4.0153\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.7598 - val_loss: 3.4492\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.2365 - val_loss: 2.9714\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7924 - val_loss: 2.5632\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.4127 - val_loss: 2.2117\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.0734 - val_loss: 1.8833\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.7313 - val_loss: 1.5178\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.3652 - val_loss: 1.1764\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 1.0579 - val_loss: 0.9079\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.8208 - val_loss: 0.7049\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 0.5507\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.4354\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.3482\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3275 - val_loss: 0.2818\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2689 - val_loss: 0.2325\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2250 - val_loss: 0.1944\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1916 - val_loss: 0.1663\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1666 - val_loss: 0.1455\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1478 - val_loss: 0.1301\n",
      "Epoch 34/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1339 - val_loss: 0.1183\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1099\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1038\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.0993\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1063 - val_loss: 0.0961\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.0938\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1012 - val_loss: 0.0921\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.0908\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 0.0900\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.0893\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.0888\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0884\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.0880\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0877\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0951 - val_loss: 0.0873\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.0870\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.0867\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.0864\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.0861\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0932 - val_loss: 0.0858\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.0854\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.0851\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.0847\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0843\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0839\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0836\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0831\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0827\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0823\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0819\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0814\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0810\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0805\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0800\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0795\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0790\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0786\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0780\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0775\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0769\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0764\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0758\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0753\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0747\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0741\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0735\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0728\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0722\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0710\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0703\n",
      "Epoch 85/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0697\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0690\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0682\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0676\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0668\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0662\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0654\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0647\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0639\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0632\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0624\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.0617\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0610\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.0601\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0594\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.0586\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0629 - val_loss: 0.0578\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0620 - val_loss: 0.0571\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0612 - val_loss: 0.0562\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0555\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0547\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0530\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0522\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0559 - val_loss: 0.0514\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0550 - val_loss: 0.0507\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0499\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.0491\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.0484\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0476\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0507 - val_loss: 0.0469\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.0461\n",
      "Epoch 117/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.0454\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0446\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0439\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0432\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0426\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0418\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0412\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0406\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0399\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0393\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0387\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0382\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0376\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0372\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0365\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0361\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0355\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0351\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0346\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0341\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0338\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0332\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0328\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0325\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0323\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0317\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0314\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0309\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0307\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0300\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.0296\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0294\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0288\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0287\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0283\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0279\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0278\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0274\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0271\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0270\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0266\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0266\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0261\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0260\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0256\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0254\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0253\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0250\n",
      "Epoch 168/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0247\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0243\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0241\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0240\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0238\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0240\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0239\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0235\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0235\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0233\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0232\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0229\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0229\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0230\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0228\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0227\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0225\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0223\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0227\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0220\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0219\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0222\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0221\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0216\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0216\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0214\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0214\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0213\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0213\n",
      "Epoch 200/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0213\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0214\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0211\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0214\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0207\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0207\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0206\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0205\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0204\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0204\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0203\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0202\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0207\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0201\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0201\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0201\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0200\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0200\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0200\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0200\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.0196\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0195\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0198\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0196\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.0195\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0195\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0193\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0194\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0193\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0193\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0197\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0195\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0192\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0191\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0194\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0191\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0197\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0189\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0189\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0190\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0189\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0194\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0189\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0188\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0188\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.0188\n",
      "Epoch 251/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0189\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0190\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0187\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0187\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0190\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0186\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0187\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0188\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0186\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.0186\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0185\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0185\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0186\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0187\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0184\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0186\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0185\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.0185\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0184\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0184\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0185\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0185\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0184\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.0185\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0184\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0184\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0188\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0183\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0183\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0185\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0184\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 283/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0183\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0183\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.0183\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0189\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.0188\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0183\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0183\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0184\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0184\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0183\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0183\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0184\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0183\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.0184\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0183\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.0183\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0183\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train_preproc, y_train,\n",
    "                    validation_data= (X_val_preproc, y_val),\n",
    "                    epochs=300, \n",
    "                    batch_size=16,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMLSE achieved after 300 epochs = 0.14\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluating the model\n",
    "epochs = 300\n",
    "\n",
    "res = model2.evaluate(X_val_preproc, y_val, verbose = 0)\n",
    "print(f\"RMLSE achieved after {epochs} epochs = {round(res**0.5,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Looking at the lowest loss\n",
    "minimium_rmlse_val = min(history.history['val_loss'])**0.5\n",
    "optimal_momentum = np.argmin(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13946121844145376"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.sqrt(min(history.history['val_loss']))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest RMLSE achieved = 0.139\n",
      "This was achieved at the epoch number 298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lowest RMLSE achieved = {round(minimium_rmlse_val,3)}\")\n",
    "print(f\"This was achieved at the epoch number {optimal_momentum}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded a `plot_history` function that you can use to detect overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(np.sqrt(history.history['loss']))\n",
    "    plt.plot(np.sqrt(history.history['val_loss']))\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('RMSLE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Challenging yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î **Questions to challenge yourself:**\n",
    "- Are you satisfied with your score?\n",
    "- Before publishing it, ask yourself whether you could really trust it or not?\n",
    "- Have you cross-validated your neural network? \n",
    "    - Feel free to cross-validate it manually with a *for loop* in Python to make sure that your results are robust against the randomness of a _train-val split_ before before submitting to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function `evaluate_model` following the framework below üëá then use a for loop with `KFold` to manually cross validate your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, train_index, val_index):\n",
    "    \n",
    "    # Slicing the training set and the validation set\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    # Preprocessing \n",
    "    preproc = create_preproc(X_train)\n",
    "    preproc.fit(X_train, y_train)\n",
    "    X_train_preproc = preproc.transform(X_train)\n",
    "    X_val_preproc = preproc.transform(X_val)\n",
    "    \n",
    "    # Training the model on the preprocessed training dataset\n",
    "    model = initialize_model(X_train_preproc)\n",
    "    \n",
    "    history = model.fit(X_train_preproc,\n",
    "                        y_train,\n",
    "                        validation_data = (X_val_preproc, y_val),\n",
    "                        epochs = 100,\n",
    "                        batch_size=16,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluating the model on the preprocessed validation dataset\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "                'rmsle_final_epoch': [model.evaluate(X_val_preproc, y_val)**0.5],\n",
    "                'rmsle_min': [np.argmin(history.history['val_loss'])**0.5]\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = 5\n",
    "kf = KFold(n_splits = cv, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4 5 6 7] [1 2]\n",
      "[0 1 2 4 5 6] [3 7]\n",
      "[0 1 2 3 6 7] [4 5]\n",
      "[1 2 3 4 5 6 7] [0]\n",
      "[0 1 2 3 4 5 7] [6]\n"
     ]
    }
   ],
   "source": [
    "kf_test = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "C = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "\n",
    "for train, test in kf_test.split(C):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOLD NUMBER 1\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0480\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOLD NUMBER 2\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0830\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOLD NUMBER 3\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0635\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOLD NUMBER 4\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0362\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOLD NUMBER 5\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 145.2382\n",
      "CPU times: user 1min 59s, sys: 40.1 s, total: 2min 39s\n",
      "Wall time: 2h 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "fold_number = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "#     print(train_index)\n",
    "#     print((train_index, val_index))\n",
    "    print(\"-\"*100)\n",
    "    print(f\"FOLD NUMBER {fold_number}\")\n",
    "    results.append(evaluate_model(X, y, train_index, val_index))\n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat(results, axis = 0)\n",
    "final_results.index = np.arange(0, len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   rmsle_final_epoch  rmsle_min\n",
       " 0           0.219614   9.949874,\n",
       "    rmsle_final_epoch  rmsle_min\n",
       " 0           0.275096   9.949874,\n",
       "    rmsle_final_epoch  rmsle_min\n",
       " 0           0.234009   9.949874,\n",
       "    rmsle_final_epoch  rmsle_min\n",
       " 0            0.25079   9.949874,\n",
       "    rmsle_final_epoch  rmsle_min\n",
       " 0           0.270808   9.949874]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmsle_final_epoch</th>\n",
       "      <th>rmsle_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219614</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275096</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.234009</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250790</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.270808</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmsle_final_epoch  rmsle_min\n",
       "0           0.219614   9.949874\n",
       "1           0.275096   9.949874\n",
       "2           0.234009   9.949874\n",
       "3           0.250790   9.949874\n",
       "4           0.270808   9.949874"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) (Bonus) Using all your CPU cores to run Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• **BONUS** üî• **Multiprocessing computing using [dask](https://docs.dask.org/en/latest/delayed.html)** and **all your CPU cores**:\n",
    "\n",
    "_(to mimic SkLearn's `n_jobs=-1`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 12:43:31.047937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 12:43:37.223447: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 919us/step - loss: 0.0765\n",
      "10/10 [==============================] - 0s 689us/step - loss: 0.0777\n",
      "10/10 [==============================] - 0s 731us/step - loss: 0.0649\n",
      "10/10 [==============================] - 0s 786us/step - loss: 0.0542\n",
      "10/10 [==============================] - 0s 677us/step - loss: 0.0669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmsle_final_epoch</th>\n",
       "      <th>rmsle_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276619</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.232903</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.254842</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278680</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.258699</td>\n",
       "      <td>9.949874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmsle_final_epoch  rmsle_min\n",
       "0           0.276619   9.949874\n",
       "1           0.232903   9.949874\n",
       "2           0.254842   9.949874\n",
       "3           0.278680   9.949874\n",
       "4           0.258699   9.949874"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from dask import delayed\n",
    "\n",
    "cv = 5\n",
    "kf = KFold(n_splits = cv, shuffle = True)\n",
    "f = delayed(evaluate_model)\n",
    "\n",
    "results = delayed([f(X, y, train_index, val_index) for (train_index, val_index) in kf.split(X)\n",
    "                  ]).compute(\n",
    "                      scheduler='processes', num_workers=8)\n",
    "\n",
    "pd.concat(results, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (2.4) (Bonus) Multiprocessing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "**multiprocessing with default Python library**\n",
    "\n",
    "References :\n",
    "* [Yitong Ren - Speeding Up and Perfecting Your Work Using Parallel Computing](https://towardsdatascience.com/speeding-up-and-perfecting-your-work-using-parallel-computing-8bc2f0c073f8)\n",
    "* [Johaupt Github - Parallel Processing for Cross Validation - BROKEN LINK](https://johaupt.github.io/python/parallel%20processing/cross-validation/multiprocessing_cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'evaluate_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/bingobango/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Wait for all tasks to complete at this point\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m pool\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/multiprocessing/pool.py:665\u001b[0m, in \u001b[0;36mPool.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (CLOSE, TERMINATE):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn unknown state\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_handler\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_handler\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This code will fail try to debug it yourself if you cannot checkout the hints below\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(processes=2) #mp.cpu_count()-1)\n",
    "\n",
    "results = []\n",
    "def log_result(x):\n",
    "    results.append(x)\n",
    "    \n",
    "for train_index, val_index in kf.split(X):\n",
    "    pool.apply_async(\n",
    "        evaluate_model,\n",
    "        args=(X, y, train_index, val_index),\n",
    "        callback = log_result)\n",
    "\n",
    "# Close the pool for new tasks\n",
    "pool.close()\n",
    "\n",
    "# Wait for all tasks to complete at this point\n",
    "pool.join()\n",
    "\n",
    "result = pd.concat(results, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>Hints</summary>\n",
    "\n",
    "This is a limitation of multiprocessing in ipython enviroments this code would work fine in .py file.\n",
    "The key error is `AttributeError: Can't get attribute 'evaluate_model' on <module 'main' (built-in)>`\n",
    "\n",
    "Checkout this stackoverflow for a workaround https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror !\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) üèÖFINAL SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü¶Ñ Predict the ***prices of the houses in your test set*** and submit your results to Kaggle! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
    "# X_test_preproc = preproc.transform(X_test)\n",
    "# ALREADY DONE ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[118088.195],\n",
       "       [150219.77 ],\n",
       "       [181401.58 ],\n",
       "       ...,\n",
       "       [149420.95 ],\n",
       "       [104600.516],\n",
       "       [187662.47 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicitons = model2.predict(X_test_preproc)\n",
    "predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 160)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preproc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Id'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíæ Save your predictions in a Dataframe called `results` with the format required by Kaggle so that when you export it to a `.csv`, Kaggle can read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>116142.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>148600.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>170801.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>192968.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>201879.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>74789.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>68278.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>147354.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>108203.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>199187.140625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  116142.679688\n",
       "1     1462  148600.734375\n",
       "2     1463  170801.140625\n",
       "3     1464  192968.156250\n",
       "4     1465  201879.828125\n",
       "...    ...            ...\n",
       "1454  2915   74789.882812\n",
       "1455  2916   68278.351562\n",
       "1456  2917  147354.640625\n",
       "1457  2918  108203.359375\n",
       "1458  2919  199187.140625\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([X_test['Id'], pd.Series(predicitons[:,0], name='SalePrice')], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì§  Export your results using Kaggle's submission format and submit it online!\n",
    "\n",
    "_(Uncomment the last cell of this notebook)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"submission_final.csv\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üèÅ Congratulations!\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... it's time for the Recap!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
