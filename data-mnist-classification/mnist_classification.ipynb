{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ <b><u>Exercise objectives</u></b>\n",
    "- Understand the *MNIST* dataset \n",
    "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
    "    - what are *Convolutional Layers*? \n",
    "    - how many *parameters* are involved in such a layer?\n",
    "- Train this CNN on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ <b><u>Let's get started!</u></b>\n",
    "\n",
    "Imagine that we are  back in time into the 90's.\n",
    "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
    "\n",
    "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
    "\n",
    "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Number recognition](recognition.gif)\n",
    "\n",
    "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î <b><u>How does this CNN work ?</u></b>\n",
    "\n",
    "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
    "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
    "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
    "\n",
    "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
    "- *Vectors*: `boston_housing` (regression)\n",
    "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
    "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
    "\n",
    "\n",
    "üíæ You can **load the MNIST dataset** with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "\n",
    "# Loading the MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
    "\n",
    "üñ® Print some images from the *train set*.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hints</i></summary>\n",
    "\n",
    "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
    "\n",
    "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "number_of_train_images = len(X_train)\n",
    "number_of_images_to_show = 3\n",
    "\n",
    "random_list_of_images_to_show = np.random.randint(0, number_of_train_images, number_of_images_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in random_list_of_images_to_show:\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
    "\n",
    "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
    "* The `RBG` intensities are coded between 0 and 255. \n",
    "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
    "\n",
    "Don't forget to do it both on your train data and your test data.\n",
    "\n",
    "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
    "\n",
    "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
    "\n",
    "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
    "\n",
    "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
    "<br>\n",
    "<details>\n",
    "    <summary><i>Answer<i></summary>\n",
    "        \n",
    "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
    "        \n",
    "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
    "        \n",
    "    * In comparison, colored pictures need multiple channels:\n",
    "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
    "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
    "        \n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: expanding dimensions** ‚ùì\n",
    "\n",
    "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
    "\n",
    "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = expand_dims(X_train, axis=-1)\n",
    "X_test = expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to for a multiclass classification task in Deep Leaning:\n",
    "\n",
    "üëâ _\"one-hot-encode\" the categories*_\n",
    "\n",
    "‚ùì **Question: encoding the labels** ‚ùì \n",
    "\n",
    "* Use **`to_categorical`** to transform your labels. \n",
    "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that you correctly used to_categorical\n",
    "assert(y_train_cat.shape == (60000,10))\n",
    "assert(y_test_cat.shape == (10000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Architecture and compilation of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
    "\n",
    "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
    "\n",
    "\n",
    "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
    "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
    "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "\n",
    "\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
    "- a last (predictive) layer that is suited for your task\n",
    "\n",
    "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
    "* optimizes the `categorical_crossentropy` loss function,\n",
    "* with the `adam` optimizer, \n",
    "* and the `accuracy` as the metrics\n",
    "\n",
    "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(8, (4,4), input_shape=(28,28,1), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    ### Second Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    \n",
    "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    ### Model compilation\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
    "\n",
    "How many trainable parameters are there in your model?\n",
    "1. Compute them with ***model.summary( )*** first\n",
    "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 8)         136       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,264\n",
      "Trainable params: 9,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Conv2D\n",
    "first_layer_weights = 8 * (4*4) * 1 + 8\n",
    "first_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second Conv2D\n",
    "second_layer_weights = 16 * (3*3) * 8 + 16\n",
    "second_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third Conv2D\n",
    "third_layer_weights = 10 * 7 * 7 * 16 + 10\n",
    "third_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense Layer\n",
    "dense_layer_weights = 10 * 10 + 10\n",
    "dense_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9264"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_weights = first_layer_weights + second_layer_weights + third_layer_weights + dense_layer_weights\n",
    "total_number_of_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: training a CNN** ‚ùì \n",
    "\n",
    "Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
    "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2625/2625 [==============================] - 17s 6ms/step - loss: 0.3918 - accuracy: 0.8790 - val_loss: 0.1715 - val_accuracy: 0.9487\n",
      "Epoch 2/10\n",
      "2625/2625 [==============================] - 17s 6ms/step - loss: 0.1495 - accuracy: 0.9559 - val_loss: 0.1295 - val_accuracy: 0.9614\n",
      "Epoch 3/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.1090 - accuracy: 0.9675 - val_loss: 0.1133 - val_accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.0872 - accuracy: 0.9732 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
      "Epoch 5/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.0752 - accuracy: 0.9772 - val_loss: 0.0901 - val_accuracy: 0.9729\n",
      "Epoch 6/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.0658 - accuracy: 0.9800 - val_loss: 0.0833 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 0.0844 - val_accuracy: 0.9742\n",
      "Epoch 8/10\n",
      "2625/2625 [==============================] - 16s 6ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.0734 - val_accuracy: 0.9781\n",
      "Epoch 9/10\n",
      "2625/2625 [==============================] - 17s 7ms/step - loss: 0.0473 - accuracy: 0.9854 - val_loss: 0.0813 - val_accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "2625/2625 [==============================] - 17s 7ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.0782 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "es = EarlyStopping(patience=3)\n",
    "\n",
    "history = model.fit(X_train, y_train_cat,\n",
    "                   validation_split=0.3,\n",
    "                   batch_size=16,\n",
    "                   epochs=10,\n",
    "                   callbacks=[es],\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
    "\n",
    "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
    "    \n",
    "Remember that we've just trained our CNN model on $60000$ training images\n",
    "\n",
    "If the chosen batch size is 32: \n",
    "\n",
    "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
    "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
    "\n",
    "\n",
    "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
    "\n",
    "What is your **`accuracy on the test set?`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 28, 28, 1), dtype=float64, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06352439522743225, 0.9801999926567078]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
    "\n",
    "üî• You solved what was a very hard problem 30 years ago with your own CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations!**\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
