{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first embedding\n",
    "\n",
    "## Exercise objectives:\n",
    "- Run your first RNN for NLP\n",
    "- Get a first taste of what an embedding is\n",
    "\n",
    "<hr>\n",
    "\n",
    "Words are not something you can easily feed to a Neural Network. For this reason, we have to convert them to something more meaningful. \n",
    "\n",
    "And this is exactly what _Embeddings_ are for! They map any word onto a vectorial representation (this a fancy way to represent each word with a vector ;) ). For instance, the word `dog` can be represented by the vector $(w_1, w_2, ..., w_n)$ in the embedding space, and we will learn the weights $(w_k)_k$.\n",
    "\n",
    "So let's just do it.\n",
    "\n",
    "\n",
    "# The data\n",
    "\n",
    "\n",
    "❓ **Question** ❓ Let's first load the data. You don't have to understand what is going on in the function, it does not matter here.\n",
    "\n",
    "⚠️ **Warning** ⚠️ The `load_data` function has a `percentage_of_sentences` argument. Depending on your computer, there are chances that too many sentences will make your compute slow down, or even freeze - your RAM can overflow. For that reason, **you should start with 10% of the sentences** and see if your computer handles it. Otherwise, rerun with a lower number. \n",
    "\n",
    "⚠️ **DISCLAIMER** ⚠️ **No need to play _who has the biggest_ (RAM) !** The idea is to get to run your models quickly to prototype. Even in real life, it is recommended that you start with a subset of your data to loop and debug quickly. So increase the number only if you are into getting the best accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 09:44:27.942617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 09:44:36.500280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "### Just run this cell to load the data ###\n",
    "###########################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "  \n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "    \n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have loaded the data, let's check it out!\n",
    "\n",
    "❓ **Question** ❓ You can play with the data here. In particular, `X_train` and `X_test` are lists of sentences. Let's print some of them, with their respective label stored in `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['poor', 'shirley', 'maclaine', 'tries', 'hard', 'to', 'lend', 'some', 'gravitas', 'to', 'this', 'mawkish', 'gag', 'inducing', 'feel', 'good', 'movie', 'but', \"she's\", 'trampled', 'by', 'the', 'run', 'away', 'sentimentality', 'of', 'a', 'film', \"that's\", 'not', 'the', 'least', 'bit', 'grounded', 'in', 'reality', 'br', 'br', 'this', 'was', 'directed', 'by', 'curtis', 'hanson', 'did', 'he', 'have', 'a', 'lobotomy', 'since', 'we', 'last', 'heard', 'from', 'him', 'hanson', 'can', 'do', 'effective', 'drama', 'sprinkled', 'with', 'comedy', 'as', 'evidenced', 'by', 'wonder', 'boys', 'so', 'i', \"don't\", 'know', 'what', 'happened', 'to', 'him', 'here', 'this', 'is', 'the', 'kind', 'of', 'movie', 'that', \"doesn't\", 'want', 'to', 'accept', 'that', 'life', 'is', 'messy', 'and', 'fussy', 'and', 'that', 'neat', 'tidy', 'endings', 'however', 'implausible', 'they', 'might', 'be', 'might', 'make', 'for', 'a', 'nice', 'closing', 'shot', 'but', 'come', 'across', 'as', 'utterly', 'phony', 'if', 'the', 'people', 'watching', 'the', 'film', 'have', 'been', 'through', 'anything', 'remotely', 'like', 'what', 'the', 'characters', 'in', 'the', 'film', 'go', 'through', 'br', 'br', 'my', 'wife', 'and', 'i', 'made', 'a', 'game', 'of', 'calling', 'out', 'the', 'plot', 'points', 'before', 'they', 'occurred', 'e', 'g', 'the', 'old', \"man's\", 'going', 'to', 'teach', 'her', 'to', 'read', 'and', 'then', 'drop', 'dead', 'bingo', 'this', 'is', 'one', 'of', 'those', 'movies', 'where', 'the', 'characters', 'give', 'little', 'speeches', 'summarizing', 'their', 'emotional', 'problems', 'making', 'you', 'wonder', 'why', 'they', 'still', 'have', 'emotional', 'problems', 'if', \"they're\", 'that', 'aware', 'of', \"what's\", 'causing', 'them', 'toni', 'collette', 'a', 'fine', 'actress', 'by', 'the', 'way', 'and', 'one', 'of', 'my', 'favorites', 'if', 'not', 'given', 'a', 'lot', 'to', 'work', 'with', 'here', 'gives', 'a', 'speech', 'early', 'on', 'about', 'why', 'she', 'buys', 'so', 'many', 'shoes', 'and', 'never', 'wears', 'them', 'spelling', 'out', 'in', 'flashing', 'neon', 'the', \"film's\", 'awkward', 'connecting', 'motif', 'at', 'that', 'moment', 'i', 'knew', 'what', 'i', 'was', 'in', 'for', 'and', 'the', 'film', 'was', 'a', 'downward', 'spiral', 'from', 'there', 'br', 'br', 'grade', 'c']\n"
     ]
    }
   ],
   "source": [
    "# print(y_train[6])\n",
    "\n",
    "print(y_test[3], X_test[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LABELS**, the task is a binary classification problem:\n",
    "- label 0 corresponds to a negative movie review\n",
    "- label 1 corresponds to a positive movie review\n",
    "\n",
    "**INPUTS**: The data has been partially cleaned! So you don't have to worry about it in this exercise. But don't forget this step in real-life challenges. \n",
    "\n",
    "Remember that words are not computer-compatible materials? You have to tokenize them!\n",
    "\n",
    "❓ **Question** ❓ Run the following cell to tokenize your sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# This initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set!\n",
    "# This tokenization also lowercases your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "# Transforms each text in texts to a sequence of integers\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Print some of the tokenized sentences to be sure you got what you expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : during -> Token : 296\n",
      "Word : a -> Token : 2\n",
      "Word : sleepless -> Token : 12160\n",
      "Word : night -> Token : 276\n",
      "Word : i -> Token : 9\n",
      "Word : was -> Token : 13\n",
      "Word : switching -> Token : 6079\n",
      "Word : through -> Token : 137\n",
      "Word : the -> Token : 1\n",
      "Word : channels -> Token : 4934\n",
      "Word : found -> Token : 260\n",
      "Word : this -> Token : 11\n",
      "Word : embarrassment -> Token : 3647\n",
      "Word : of -> Token : 4\n",
      "Word : a -> Token : 2\n",
      "Word : movie -> Token : 18\n",
      "Word : what -> Token : 46\n",
      "Word : were -> Token : 69\n",
      "Word : they -> Token : 32\n",
      "Word : thinking -> Token : 517\n",
      "Word : br -> Token : 7\n",
      "Word : br -> Token : 7\n",
      "Word : if -> Token : 41\n",
      "Word : this -> Token : 11\n",
      "Word : is -> Token : 6\n",
      "Word : life -> Token : 109\n",
      "Word : after -> Token : 104\n",
      "Word : remote -> Token : 3061\n",
      "Word : control -> Token : 987\n",
      "Word : for -> Token : 15\n",
      "Word : kari -> Token : 9605\n",
      "Word : wuhrer -> Token : 16769\n",
      "Word : salin -> Token : 16770\n",
      "Word : no -> Token : 53\n",
      "Word : wonder -> Token : 574\n",
      "Word : she's -> Token : 480\n",
      "Word : gone -> Token : 831\n",
      "Word : nowhere -> Token : 1351\n",
      "Word : br -> Token : 7\n",
      "Word : br -> Token : 7\n",
      "Word : and -> Token : 3\n",
      "Word : why -> Token : 135\n",
      "Word : did -> Token : 116\n",
      "Word : david -> Token : 568\n",
      "Word : keith -> Token : 4512\n",
      "Word : take -> Token : 202\n",
      "Word : this -> Token : 11\n",
      "Word : role -> Token : 203\n",
      "Word : it's -> Token : 44\n",
      "Word : pathetic -> Token : 928\n"
     ]
    }
   ],
   "source": [
    "# sentence_number = 100\n",
    "\n",
    "input_raw = X_train[10]\n",
    "input_token = X_train_token[10]\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(50):\n",
    "    print(f\"Word : {input_raw[i]} -> Token : {input_token[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary that maps each word to a token can be accessed with `tokenizer.word_index`\n",
    "    \n",
    "❓ **Question** ❓ Add a `vocab_size` variable that stores the number of different words (=tokens) in the train set. This is called the _size of the vocabulary_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30419 different words in the training set\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "\n",
    "print(f\"There are {vocab_size} different words in the training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `X_train_token` and `X_test_token` contain sequences of different lengths.\n",
    "\n",
    "<img src=\"padding.png\" alt='Word2Vec' width=\"700px\" />\n",
    "\n",
    "However, a neural network has to have a tensor as input. For this reason, you have to pad your data.\n",
    "\n",
    "❓ **Question** ❓  Pad your data with the `pad_sequences` function (documentation [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)). Do not forget about the `dtype` and `padding` keywords (but do not use `maxlen` here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The RNN\n",
    "\n",
    "Let's now feed this data to a Recurrent Neural Network.\n",
    "\n",
    "❓ **Question** ❓ Write a model that has:\n",
    "- an embedding layer whose `input_dim` is the size of your vocabulary (= your `vocab_size`), and whose `output_dim` is the size of the embedding space you want to have\n",
    "- a RNN (SimpleRNN, LSTM, GRU) layer\n",
    "- a Dense layer\n",
    "- an output layer\n",
    "\n",
    "⚠️ **Warning** ⚠️ Here, you don't need a masking layer. Why? Because `layers.Embedding` has a argument to do that directly, which you have to set with `mask_zero=True`. That also means that your data **HAS TO** be padded with **0** (which is the default behavior). See the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#example_2) to understand how it **impacts** the `input_dim`.\n",
    "\n",
    "<details>\n",
    "    <summary>💡 Hint</summary>\n",
    "\n",
    "`input_dim` should equal size of vocabulary + 1\n",
    "\n",
    "</details>\n",
    "\n",
    "Compile it with the appropriate arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Size = Maximum Integer Index + 1\n",
    "\n",
    "# Example:\n",
    "# a[0] = 'item 1'\n",
    "# a[1] = 'item 2'\n",
    "# a[2] = 'item 3'\n",
    "# ................\n",
    "# Maximum Integer Index = 2\n",
    "# Vocabulary Size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# After padding, masking informs the model that some of the data is padded and therefore must be ignored\n",
    "# Embedding - Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "embedding_dimension = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size+1, output_dim=embedding_dimension, mask_zero=True))\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "          \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output-dim -  the number of dimensions we wish to embed into. Each word will be represented by a vector of this many dimensions.\n",
    "# Test different values\n",
    "\n",
    "# Embedding layer is a compression of the input, when the layer is smaller , you compress more and lose more data. \n",
    "# When the layer is bigger you compress less and potentially overfit your input dataset to this layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Look at the number of parameters in your RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          1521000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                5680      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,526,901\n",
      "Trainable params: 1,526,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Double-check that the number of parameters in your embedding layer is equal to the (number of words in your vocabulary + 1 for the masking value) $\\times$  the dimension of your embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of parameters : 1521000\n"
     ]
    }
   ],
   "source": [
    "print(f'Expected number of parameters : {(vocab_size + 1) * embedding_dimension}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Start fitting your model with 20 epochs, with an early stopping criterion whose patience is equal to 4.\n",
    "\n",
    "⚠️ **Warning** ⚠️ You might see that it takes a lot of time! \n",
    "\n",
    "**So stop it after a couple of iterations!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 64/110 [================>.............] - ETA: 15s - loss: 0.6906 - accuracy: 0.5410"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      3\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_pad,\n\u001b[1;32m      6\u001b[0m                     y_train, \n\u001b[1;32m      7\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, \n\u001b[1;32m      8\u001b[0m                     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,\n\u001b[1;32m      9\u001b[0m                     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     callbacks \u001b[38;5;241m=\u001b[39m [es])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/tom/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 4, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad,\n",
    "                    y_train, \n",
    "                    batch_size=16, \n",
    "                    validation_split=0.3,\n",
    "                    epochs = 20,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not waste too much time just staring at our screen or having coffees. It is too early to start having breaks ;)\n",
    "\n",
    "❓ **Question** ❓ We will reduce the computational time. To start, let's first look at how many words there are in the different sentences of your train set (Just run the following cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ = [len(_) for _ in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAGzCAYAAABejHGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFc0lEQVR4nO3deVhV1eL/8c8BZFAERBnEHBC9qWlpkIqzSaJRZjmWeXH2lmbmzC0tU8Nsnpwa1GuaQ3OWmqmp3XDWckotx/QCmgEOOQDr90df9s8jg6gI6H6/nodHWXudvddaZ5+9P+zpOIwxRgAAALAFl6JuAAAAAAoP4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANjIdQ9/VapUUY8ePa73YmzvpZdeUtWqVeXq6qq6dete8eu///57ORwOffzxxwXfuBuAw+HQwIEDi7oZ+ZKenq4RI0aoYsWKcnFxUfv27Yu6SchFcfhcValSRffdd1+RLb+4Yx915YrDen0lkpKS1LFjR5UtW1YOh0Ovv/56UTcp31q0aKEWLVoU+HyvKPzNnDlTDodDGzduzHF6ixYtVLt27Wtu1DfffKPnnnvumudjF99++61GjBihxo0ba8aMGXrhhRdyrTt37twbasVHdh988IFeeukldezYUbNmzdJTTz1V1E1ysnPnTj333HM6cOBAUTel0BTm54rtI3BlnnrqKS1dulRxcXGaPXu22rRpU9RNKnJu13sBu3fvlovLlR1g/Oabb/TOO++wgcunFStWyMXFRe+//77c3d3zrDt37lxt375dgwcPLpzGocCtWLFCFSpU0GuvvVbUTcnRzp07NXbsWLVo0UJVqlQp6uYUisL8XLF9LFhXs4/CjWXFihV64IEHNGzYsKJuSrFx3dd4Dw8PlShR4novpkCdPn26qJtwRZKTk+Xl5XXZ4IeidfbsWWVmZl7zfJKTk+Xn53ftDQJwQ+6j7KKg9sXFeZtZVHmj0K/5u3DhgsaOHavq1avL09NTZcuWVZMmTbRs2TJJUo8ePfTOO+9I+vs6rKyfLKdPn9bQoUNVsWJFeXh46NZbb9XLL78sY4zTcv/66y8NGjRI5cqVU+nSpdWuXTsdOXJEDofD6S/m5557Tg6HQzt37tQjjzyiMmXKqEmTJpKkn3/+WT169FDVqlXl6emp4OBg9erVS3/88YfTsrLmsWfPHj366KPy9fVVQECARo8eLWOMDh8+rAceeEA+Pj4KDg7WK6+8kq+xS09P17hx4xQWFiYPDw9VqVJF//73v3Xu3DmrjsPh0IwZM3T69GlrrGbOnJnj/Fq0aKGvv/5aBw8etOpeemQmMzNTEyZM0C233CJPT0+1atVKv/76a7Z5rVu3Tm3atJGvr69Kliyp5s2b67///e9l+5R1rciCBQsuu5zcrsW59BqIi+c5duxYVahQQaVLl1bHjh2Vmpqqc+fOafDgwQoMDJS3t7d69uzpNIYXmzNnjm699VZ5enoqPDxcq1evzlbnyJEj6tWrl4KCguTh4aHbbrtNH3zwQY79nDdvnp555hlVqFBBJUuWVFpaWq5jc7l1+8CBA3I4HFq5cqV27NhhvYfff/99rvPcuHGjoqOjVa5cOXl5eSk0NFS9evVyqpOZmanXX39dt912mzw9PRUUFKT+/fvrzz//dKqXde3YDz/8oPr168vT01NVq1bVf/7zH6vOzJkz1alTJ0lSy5Ytc2zj4sWL1bRpU5UqVUqlS5dWTEyMduzY4bSsHj16yNvbW0eOHFH79u3l7e2tgIAADRs2TBkZGdna/8Ybb6hOnTry9PRUQECA2rRpk+3ylA8//FDh4eHy8vKSv7+/unbtqsOHDzvV2bt3rzp06KDg4GB5enrqlltuUdeuXZWamprrGBfU52rNmjXq1KmTKlWqJA8PD1WsWFFPPfWU/vrrL6dxyWv7mJe83jdJOnHihIYNG6Y6derI29tbPj4+atu2rX766SerTlJSktzc3DR27Nhs89+9e7ccDofefvttqywlJUWDBw+21ulq1arpxRdfzNcfQV988YViYmIUEhIiDw8PhYWFady4cdne/9x8//33ioiIkKenp8LCwjRt2jRrW32xi7czGzdulMPh0KxZs7LNb+nSpXI4HFq0aJFVdiXbgvxs83KS1eZff/1VPXr0kJ+fn3x9fdWzZ0+dOXPGqpe1fchp+5/bfu9a91kZGRn697//reDgYJUqVUrt2rXL9pmS8re/yGtfnJt9+/apU6dO8vf3V8mSJdWwYUN9/fXX1vSsS9WMMXrnnXcu+3m588479dBDDzmV1alTRw6HQz///LNVNn/+fDkcDu3atcsq27Jli9q2bSsfHx95e3urVatWWrt2rdO8stqzatUqPf744woMDNQtt9xiTZ8+fbrCwsLk5eWl+vXra82aNTm286233tJtt92mkiVLqkyZMoqIiNDcuXPzHKtLXdVp39TUVB0/fjxb+YULFy772ueee07x8fHq06eP6tevr7S0NG3cuFGbN2/WPffco/79++vo0aNatmyZZs+e7fRaY4zatWunlStXqnfv3qpbt66WLl2q4cOH68iRI06nwXr06KEFCxaoe/fuatiwoVatWqWYmJhc29WpUydVr15dL7zwgrWzXbZsmfbt26eePXsqODhYO3bs0PTp07Vjxw6tXbs220rUpUsX1axZUxMnTtTXX3+t8ePHy9/fX9OmTdPdd9+tF198UXPmzNGwYcN01113qVmzZnmOVZ8+fTRr1ix17NhRQ4cO1bp16xQfH69du3bps88+kyTNnj1b06dP1/r16/Xee+9Jkho1apTj/J5++mmlpqbq999/t8bK29vbqc7EiRPl4uKiYcOGKTU1VZMmTVK3bt20bt06q86KFSvUtm1bhYeH69lnn5WLi4tmzJihu+++W2vWrFH9+vXz7Fd+l3Ol4uPj5eXlpVGjRunXX3/VW2+9pRIlSsjFxUV//vmnnnvuOa1du1YzZ85UaGioxowZ4/T6VatWaf78+Ro0aJA8PDw0efJktWnTRuvXr7euZU1KSlLDhg2tG0QCAgK0ePFi9e7dW2lpadlO+40bN07u7u4aNmyYzp07l+vR2fys2wEBAZo9e7YmTJigU6dOKT4+XpJUs2bNHOeZnJys1q1bKyAgQKNGjZKfn58OHDigTz/91Kle//79NXPmTPXs2VODBg3S/v379fbbb2vLli3673//63RU5Ndff1XHjh3Vu3dvxcbG6oMPPlCPHj0UHh6u2267Tc2aNdOgQYP05ptv6t///rfVtqx/Z8+erdjYWEVHR+vFF1/UmTNnNGXKFDVp0kRbtmxxCk0ZGRmKjo5WgwYN9PLLL+u7777TK6+8orCwMD322GNWvd69e2vmzJlq27at+vTpo/T0dK1Zs0Zr165VRESEJGnChAkaPXq0OnfurD59+ujYsWN666231KxZM23ZskV+fn46f/68oqOjde7cOT3xxBMKDg7WkSNHtGjRIqWkpMjX1zfHcS6oz9XChQt15swZPfbYYypbtqzWr1+vt956S7///rsWLlxovVe5bR/zcrn3Tfp7R/r555+rU6dOCg0NVVJSkqZNm6bmzZtr586dCgkJUVBQkJo3b64FCxbo2WefdVrG/Pnz5erqaoX/M2fOqHnz5jpy5Ij69++vSpUq6ccff1RcXJz+97//XfYayZkzZ8rb21tDhgyRt7e3VqxYoTFjxigtLU0vvfRSnq/dsmWL2rRpo/Lly2vs2LHKyMjQ888/r4CAgDxfFxERoapVq2rBggWKjY3N1r8yZcooOjpa0pVvC651m9e5c2eFhoYqPj5emzdv1nvvvafAwEC9+OKL+Xp9Tq51nzVhwgQ5HA6NHDlSycnJev311xUVFaWtW7fKy8tL0pXvL3LaF+ckKSlJjRo10pkzZzRo0CCVLVtWs2bNUrt27fTxxx/rwQcfVLNmzTR79mx1795d99xzj/75z3/mOR5NmzbVRx99ZP1+4sQJ7dixQy4uLlqzZo1uv/12SX//oRYQEGBt13bs2KGmTZvKx8dHI0aMUIkSJTRt2jS1aNFCq1atUoMGDZyW8/jjjysgIEBjxoyxjvy9//776t+/vxo1aqTBgwdr3759ateunfz9/VWxYkXrte+++64GDRqkjh076sknn9TZs2f1888/a926dXrkkUfy7J8TcwVmzJhhJOX5c9tttzm9pnLlyiY2Ntb6/Y477jAxMTF5LmfAgAEmp6Z9/vnnRpIZP368U3nHjh2Nw+Ewv/76qzHGmE2bNhlJZvDgwU71evToYSSZZ5991ip79tlnjSTz8MMPZ1vemTNnspV99NFHRpJZvXp1tnn069fPKktPTze33HKLcTgcZuLEiVb5n3/+aby8vJzGJCdbt241kkyfPn2cyocNG2YkmRUrVlhlsbGxplSpUnnOL0tMTIypXLlytvKVK1caSaZmzZrm3LlzVvkbb7xhJJlt27YZY4zJzMw01atXN9HR0SYzM9Oqd+bMGRMaGmruueeePJef3+UYk33dydK8eXPTvHnzbPOsXbu2OX/+vFX+8MMPG4fDYdq2bev0+sjIyGxjkLX+bty40So7ePCg8fT0NA8++KBV1rt3b1O+fHlz/Phxp9d37drV+Pr6WutMVpuqVq2a43p0qfyu21n9v/RzlpPPPvvMSDIbNmzItc6aNWuMJDNnzhyn8iVLlmQrr1y5crZ1Pzk52Xh4eJihQ4daZQsXLjSSzMqVK53mefLkSePn52f69u3rVJ6YmGh8fX2dymNjY40k8/zzzzvVrVevngkPD7d+X7FihZFkBg0alK1vWevngQMHjKurq5kwYYLT9G3bthk3NzerfMuWLUaSWbhwYfaBuoxr/VwZk/P2Jj4+3jgcDnPw4EGrLLftY27y+76dPXvWZGRkOL12//79xsPDw+l9mDZtWra2G2NMrVq1zN133239Pm7cOFOqVCmzZ88ep3qjRo0yrq6u5tChQ3m2O6fx6N+/vylZsqQ5e/Zsnq+9//77TcmSJc2RI0essr179xo3N7dsY3fpdiYuLs6UKFHCnDhxwio7d+6c8fPzM7169bLKrnRbkJ91ICdZ+5eLl22MMQ8++KApW7as9fv+/fuNJDNjxoxs88htv3e1+6ysPlWoUMGkpaVZ5QsWLDCSzBtvvGGMubL9RV774pwMHjzYSDJr1qyxyk6ePGlCQ0NNlSpVnNZlSWbAgAGXnWfWtmvnzp3GGGO+/PJL4+HhYdq1a2e6dOli1bv99tud9gvt27c37u7u5rfffrPKjh49akqXLm2aNWtmlWVlqCZNmpj09HSr/Pz58yYwMNDUrVvXaR2ZPn26keS0v3vggQfytf2/nKs67fvOO+9o2bJl2X6yUnFe/Pz8tGPHDu3du/eKl/vNN9/I1dVVgwYNciofOnSojDFavHixJGnJkiWS/k7XF3viiSdynfe//vWvbGVZf7lIf1+vdfz4cTVs2FCStHnz5mz1+/TpY/3f1dVVERERMsaod+/eVrmfn59uvfVW7du3L9e2SH/3VZKGDBniVD506FBJcjq0XZB69uzpdHSqadOmkmS1d+vWrdq7d68eeeQR/fHHHzp+/LiOHz+u06dPq1WrVlq9enW+TulcbjlX45///KfTUaoGDRrIGJPtNGeDBg10+PBhpaenO5VHRkYqPDzc+r1SpUp64IEHtHTpUmVkZMgYo08++UT333+/jDFW348fP67o6GilpqZmWy9iY2Od1qPc5HfdvhJZ17gsWrQo16PyCxculK+vr+655x6n/oSHh8vb21srV650ql+rVi3rvZKkgICAfK3P0t9H0lNSUvTwww87LcvV1VUNGjTItiwp++eyadOmTsv65JNP5HA4sh2FkmQdmf/000+VmZmpzp07Oy03ODhY1atXt5abdWRv6dKlTqfTCkJ+1veL15PTp0/r+PHjatSokYwx2rJlyzUtPz/vm4eHh3XjQ0ZGhv744w95e3vr1ltvdVqvH3roIbm5uWn+/PlW2fbt27Vz50516dLFKlu4cKGaNm2qMmXKOI17VFSUMjIycryk4mIXj8fJkyd1/PhxNW3aVGfOnNEvv/yS6+syMjL03XffqX379goJCbHKq1WrprZt2+a5TOnvo2EXLlxwOkL+7bffKiUlxerf1WwLrnWbl9Nn4Y8//sjzUpLLudZ91j//+U+VLl3a+r1jx44qX768tf+6mv1FTvvinHzzzTeqX7++06lhb29v9evXTwcOHNDOnTvzNwgXyXpPstbNNWvW6K677tI999xjnYJNSUnR9u3brboZGRn69ttv1b59e1WtWtWaV/ny5fXII4/ohx9+yPYe9e3bV66urtbvGzduVHJysv71r385rSM9evTIdsbBz89Pv//+uzZs2HDF/bvYVZ32rV+/vnU65WJZH/K8PP/883rggQf0j3/8Q7Vr11abNm3UvXv3fAXHgwcPKiQkxGllk/7/KaWDBw9a/7q4uCg0NNSpXrVq1XKd96V1pb8P+Y4dO1bz5s1TcnKy07ScrgGqVKmS0+++vr7y9PRUuXLlspVfet3gpbL6cGmbg4OD5efnZ/W1oF3ahzJlykiSdf1XVmi/9JTIxVJTU63XXe1yrkZO4y/J6ZB5VnlmZqZSU1NVtmxZq7x69erZ5vmPf/xDZ86c0bFjx+Ti4qKUlBRNnz5d06dPz7ENl64nOa1XOcnvun0lmjdvrg4dOmjs2LF67bXX1KJFC7Vv316PPPKIPDw8JP39fqampiowMDDHeVzan0vHWPr7vcvP+5a17tx99905Tvfx8XH6Pev6vbyW9dtvvykkJET+/v55LtcYk+P7K8n6gyE0NFRDhgzRq6++qjlz5qhp06Zq166ddU3UtcjP+n7o0CGNGTNGX375ZbbxzOuaw6tZflYbLl5O1rWTkydP1v79+52urbv4c1KuXDm1atVKCxYs0Lhx4yT9fUrUzc3N6XqpvXv36ueff871VOul69alduzYoWeeeUYrVqzItvPMazySk5P1119/5bi9z2sfkOWOO+5QjRo1NH/+fCsEzZ8/X+XKlbPW3WPHjl3xtuBat3l5vf7Sz05+Xes+69LPlMPhULVq1azHPF3N/uJKtpmXnk6VnLeZV/rouaCgIFWvXl1r1qxR//79tWbNGrVs2VLNmjXTE088oX379mnXrl3KzMy0wt+xY8d05swZ3XrrrTm2JTMzU4cPH7Yur8ipj1nb90vHs0SJEk6BUpJGjhyp7777TvXr11e1atXUunVrPfLII2rcuPEV9fW6P+rlUs2aNdNvv/2mL774Qt9++63ee+89vfbaa5o6darTXyGFLaejM507d9aPP/6o4cOHq27duvL29lZmZqbatGmT49Gti5N8XmWS8ryW4WL5vZi7oFyuvVn9fumll3J9mPSl1ztdzXKk3PuekZFxRWN9re9Blqy+P/roo7luzC79IyY/R/2ul6yHsK5du1ZfffWVli5dql69eumVV17R2rVrrfU5MDBQc+bMyXEel+64r2Uss8Zv9uzZCg4Ozjbdzc15c5Tbsq5UZmamHA6HFi9enOM8L15fX3nlFfXo0cPaPg0aNEjx8fFau3at04XZV+py45aRkaF77rlHJ06c0MiRI1WjRg2VKlVKR44cUY8ePa75LvH8vG8vvPCCRo8erV69emncuHHy9/eXi4uLBg8enG35Xbt2Vc+ePbV161bVrVtXCxYsUKtWrZxCQ2Zmpu655x6NGDEix2X/4x//yLW9KSkpat68uXx8fPT8888rLCxMnp6e2rx5s0aOHFkgd83npUuXLpowYYKOHz+u0qVL68svv9TDDz9sraNXsy241u3Q5V6f1/bySuZZUNtL6er2F0W5zZSkJk2aaPny5frrr7+0adMmjRkzRrVr15afn5/WrFmjXbt2ydvbW/Xq1bvqZVxLH2vWrKndu3dr0aJFWrJkiT755BNNnjxZY8aMyfFGrNwUeviTJH9/f/Xs2VM9e/bUqVOn1KxZMz333HNW+MttJa5cubK+++47nTx50ukISdYpgMqVK1v/ZmZmav/+/U5JOj93VmX5888/tXz5co0dO9bpxoCrOV19NbL6sHfvXqcL+pOSkpSSkmL19Upda5gMCwuT9PdRmqioqGua1+WUKVNGKSkp2coPHjyY7a+hgpDTe7tnzx6VLFnSCkGlS5dWRkZGgfc9v+v21WjYsKEaNmyoCRMmaO7cuerWrZvmzZunPn36KCwsTN99950aN25cYBvd3NaxrHUnMDCwwMYvLCxMS5cu1YkTJ3I9+hcWFiZjjEJDQ/MMHFnq1KmjOnXq6JlnntGPP/6oxo0ba+rUqRo/fnyur7nWz9W2bdu0Z88ezZo1y+mi9KynIBTksnLz8ccfq2XLlnr//fedylNSUrIdCWrfvr369+9vnfrds2eP4uLinOqEhYXp1KlTV/Vef//99/rjjz/06aefOt1ksH///su+NjAwUJ6enjlu7/O7D+jSpYvGjh2rTz75REFBQUpLS1PXrl2t6QEBAddtW3C1so6eXbrNvF5niaTs20xjjH799Vcr+F7P/UXlypW1e/fubOXXus1s2rSpZsyYoXnz5ikjI0ONGjWSi4uLmjRpYoW/Ro0aWSE5ICBAJUuWzLUtLi4u2c4+5dQX6e/xvPjMyIULF7R//37dcccdTvVLlSqlLl26qEuXLjp//rweeughTZgwQXFxcfL09MxXPwv9yZaXHjr29vZWtWrVnB69UapUKUnZV+J7771XGRkZTo8SkKTXXntNDofDup4j626syZMnO9V766238t3OrDf20r92Cusp/vfee2+Oy3v11VclKc87l/NSqlSpazqFFB4errCwML388ss6depUtunHjh276nlfKiwsTGvXrtX58+etskWLFuX4KIGCkJCQ4HSdzuHDh/XFF1+odevWcnV1laurqzp06KBPPvlE27dvz/b6a+l7ftftK/Hnn39mW3+z/vrO+rx17txZGRkZ1um7i6Wnp+cYvi8nt89vdHS0fHx89MILL+R4DeLVjF+HDh1kjMnxL96svj/00ENydXXV2LFjs42HMcbaJqWlpWW7DrROnTpycXHJ9dFAWa71c5XT9sYYozfeeCPHZUnZx/daubq6ZhufhQsX6siRI9nq+vn5KTo6WgsWLNC8efPk7u6e7WsGO3furISEBC1dujTb61NSUrKN9aVtkZzH4/z589m26bm9NioqSp9//rmOHj1qlf/666/5vna2Zs2aqlOnjubPn6/58+erfPnyTiH0em4LrpaPj4/KlSuX7VrK/IzZ1frPf/6jkydPWr9//PHH+t///mdtr67n/uLee+/V+vXrlZCQYJWdPn1a06dPV5UqVVSrVq2rmm/W6dwXX3xRt99+u3XJR9OmTbV8+XJt3LjR6fpZV1dXtW7dWl988YXTtxolJSVp7ty5atKkyWVPy0dERCggIEBTp0512t/NnDkz2+f80gzl7u6uWrVqyRiTryeuZCn0I3+1atVSixYtFB4eLn9/f23cuFEff/yx0/eqZl10P2jQIEVHR8vV1VVdu3bV/fffr5YtW+rpp5/WgQMHdMcdd+jbb7/VF198ocGDB1t/ZYSHh6tDhw56/fXX9ccff1iPetmzZ4+k/P3l7OPjo2bNmmnSpEm6cOGCKlSooG+//TZff3kWhDvuuEOxsbGaPn26dQpk/fr1mjVrltq3b6+WLVte1XzDw8M1f/58DRkyRHfddZe8vb11//335/v1Li4ueu+999S2bVvddttt6tmzpypUqKAjR45o5cqV8vHx0VdffXVVbbtUnz599PHHH6tNmzbq3LmzfvvtN3344YfW+1zQateurejoaKdHvUhyChYTJ07UypUr1aBBA/Xt21e1atXSiRMntHnzZn333Xc6ceLEVS07v+v2lZg1a5YmT56sBx98UGFhYTp58qTeffdd+fj4WH9cNG/eXP3791d8fLy2bt2q1q1bq0SJEtq7d68WLlyoN954Qx07dryi5datW1eurq568cUXlZqaKg8PD919990KDAzUlClT1L17d915553q2rWrAgICdOjQIX399ddq3LhxtvB7OS1btlT37t315ptvau/evdYlGVnX6gwcOFBhYWEaP3684uLidODAAbVv316lS5fW/v379dlnn6lfv34aNmyYVqxYoYEDB6pTp076xz/+ofT0dM2ePdva0eflWj9XNWrUUFhYmIYNG6YjR47Ix8dHn3zySY7Xg+W2fbxW9913n55//nn17NlTjRo10rZt2zRnzpxcj7J36dJFjz76qCZPnqzo6OhsD9EdPny4vvzyS913333WY2VOnz6tbdu26eOPP9aBAweyHVHM0qhRI5UpU0axsbEaNGiQHA6HZs+ene9Tj88995y+/fZbNW7cWI899pj1h1Xt2rW1devWfM2jS5cuGjNmjDw9PdW7d+9s3wJyvbYF16JPnz6aOHGi+vTpo4iICK1evdra710P/v7+atKkiXr27KmkpCS9/vrrqlatmvr27Svp+u4vRo0apY8++kht27bVoEGD5O/vr1mzZmn//v365JNPrvpbW6pVq6bg4GDt3r3b6SbRZs2aaeTIkZLkFP4kafz48Vq2bJmaNGmixx9/XG5ubpo2bZrOnTunSZMmXXaZJUqU0Pjx49W/f3/dfffd6tKli/bv368ZM2Zk+/y1bt1awcHBaty4sYKCgrRr1y69/fbbiomJyXbNeJ6u5NbgrNuUc3t0RE6PoLj0Nvrx48eb+vXrGz8/P+Pl5WVq1KhhJkyY4PSIjvT0dPPEE0+YgIAA43A4nG7NP3nypHnqqadMSEiIKVGihKlevbp56aWXnG4jN8aY06dPmwEDBhh/f3/j7e1t2rdvb3bv3m0kOd3GnnV7+bFjx7L15/fffzcPPvig8fPzM76+vqZTp07m6NGjud42f+k8cnsES34f1XHhwgUzduxYExoaakqUKGEqVqxo4uLisj3m4Eoe9XLq1CnzyCOPGD8/PyPJejxF1q37lz7mIrfHB2zZssU89NBDpmzZssbDw8NUrlzZdO7c2SxfvjzP5V/pcl555RVToUIF4+HhYRo3bmw2btyY66NeLp1nbutrTu+X/u9RAB9++KGpXr268fDwMPXq1cv2uBJjjElKSjIDBgwwFStWNCVKlDDBwcGmVatWZvr06ZdtU17yu27nd/3ZvHmzefjhh02lSpWMh4eHCQwMNPfdd5/T42yyTJ8+3YSHhxsvLy9TunRpU6dOHTNixAhz9OhRq07lypVzfEzTpe+HMca8++67pmrVqsbV1TXbY19WrlxpoqOjja+vr/H09DRhYWGmR48eTu3KbZ3Oeu8ulp6ebl566SVTo0YN4+7ubgICAkzbtm3Npk2bnOp98sknpkmTJqZUqVKmVKlSpkaNGmbAgAFm9+7dxhhj9u3bZ3r16mXCwsKMp6en8ff3Ny1btjTfffdd7oP8fwric7Vz504TFRVlvL29Tbly5Uzfvn3NTz/9lK1eXtvHnOT3fTt79qwZOnSoKV++vPHy8jKNGzc2CQkJOb6/xhiTlpZmvLy8jCTz4Ycf5rjskydPmri4OFOtWjXj7u5uypUrZxo1amRefvllp21+Tv773/+ahg0bGi8vLxMSEmJGjBhhli5dmuNjhHKyfPlyU69ePePu7m7CwsLMe++9Z4YOHWo8PT2zjU9Oj5Tau3ev9QioH374IcdlXMu2IK9Hs1wst/1L1vZt//79VtmZM2dM7969ja+vryldurTp3LmzSU5OLvB9VlafPvroIxMXF2cCAwONl5eXiYmJcXosUZb87C/y2hfn5rfffjMdO3Y0fn5+xtPT09SvX98sWrQoW72s7Xt+derUyUgy8+fPt8rOnz9vSpYsadzd3c1ff/2V7TWbN2820dHRxtvb25QsWdK0bNnS/Pjjj051LpehJk+ebEJDQ42Hh4eJiIgwq1evzvb5mzZtmmnWrJk1lmFhYWb48OEmNTU13/0zxhiHMVdxFecNauvWrapXr54+/PBDdevWraibAwAoRO3bt7/qR40BN5Ob9tusL/5KpCyvv/66XFxcLvvNGgCAG9ul+4C9e/fqm2++cfpqSMCuiuRu38IwadIkbdq0SS1btpSbm5sWL16sxYsXq1+/fpe98wYAcGOrWrWq9d3sBw8e1JQpU+Tu7p7ro2cAO7lpT/suW7ZMY8eO1c6dO3Xq1ClVqlRJ3bt319NPP53teWIAgJtLz549tXLlSiUmJsrDw0ORkZF64YUXdOeddxZ104Aid9OGPwAAAGR3017zBwAAgOwIfwAAADbCxW95yMzM1NGjR1W6dOlC/45dAABwdYwxOnnypEJCQq76gc83M8JfHo4ePcqdwQAA3KAOHz6sW265paibUewQ/vKQ9VUphw8fvux38wEAgOIhLS1NFStWvLKvPLMRwl8esk71+vj4EP4AALjBcMlWzjgRDgAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEbeibgBuHFVGfV3UTbhiBybGFHUTAAAoVjjyBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgI4Q8AAMBG3Iq6AXZVZdTXRd0EAABgQxz5AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbKXbhLyMjQ6NHj1ZoaKi8vLwUFhamcePGyRhj1THGaMyYMSpfvry8vLwUFRWlvXv3Os3nxIkT6tatm3x8fOTn56fevXvr1KlThd0dAACAYqXYhb8XX3xRU6ZM0dtvv61du3bpxRdf1KRJk/TWW29ZdSZNmqQ333xTU6dO1bp161SqVClFR0fr7NmzVp1u3bppx44dWrZsmRYtWqTVq1erX79+RdElAACAYsNhLj6kVgzcd999CgoK0vvvv2+VdejQQV5eXvrwww9ljFFISIiGDh2qYcOGSZJSU1MVFBSkmTNnqmvXrtq1a5dq1aqlDRs2KCIiQpK0ZMkS3Xvvvfr9998VEhKSr7akpaXJ19dXqamp8vHxKdB+8py/wnFgYkxRNwEAUMiu5/77ZlDsjvw1atRIy5cv1549eyRJP/30k3744Qe1bdtWkrR//34lJiYqKirKeo2vr68aNGighIQESVJCQoL8/Pys4CdJUVFRcnFx0bp163Jd9rlz55SWlub0AwAAcDMpdt/wMWrUKKWlpalGjRpydXVVRkaGJkyYoG7dukmSEhMTJUlBQUFOrwsKCrKmJSYmKjAw0Gm6m5ub/P39rTo5iY+P19ixYwuyOwAAAMVKsTvyt2DBAs2ZM0dz587V5s2bNWvWLL388suaNWvWdV92XFycUlNTrZ/Dhw9f92UCAAAUpmJ35G/48OEaNWqUunbtKkmqU6eODh48qPj4eMXGxio4OFiSlJSUpPLly1uvS0pKUt26dSVJwcHBSk5Odppvenq6Tpw4Yb0+Jx4eHvLw8CjgHgEAABQfxe7I35kzZ+Ti4twsV1dXZWZmSpJCQ0MVHBys5cuXW9PT0tK0bt06RUZGSpIiIyOVkpKiTZs2WXVWrFihzMxMNWjQoBB6AQAAUDwVuyN/999/vyZMmKBKlSrptttu05YtW/Tqq6+qV69ekiSHw6HBgwdr/Pjxql69ukJDQzV69GiFhISoffv2kqSaNWuqTZs26tu3r6ZOnaoLFy5o4MCB6tq1a77v9AUAALgZFbvw99Zbb2n06NF6/PHHlZycrJCQEPXv319jxoyx6owYMUKnT59Wv379lJKSoiZNmmjJkiXy9PS06syZM0cDBw5Uq1at5OLiog4dOujNN98sii4BAAAUG8XuOX/FCc/5u/HxnD8AsB+e85e3YnfNHwAAAK4fwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALCRYhn+jhw5okcffVRly5aVl5eX6tSpo40bN1rTjTEaM2aMypcvLy8vL0VFRWnv3r1O8zhx4oS6desmHx8f+fn5qXfv3jp16lRhdwUAAKBYKXbh788//1Tjxo1VokQJLV68WDt37tQrr7yiMmXKWHUmTZqkN998U1OnTtW6detUqlQpRUdH6+zZs1adbt26aceOHVq2bJkWLVqk1atXq1+/fkXRJQAAgGLDYYwxRd2Ii40aNUr//e9/tWbNmhynG2MUEhKioUOHatiwYZKk1NRUBQUFaebMmeratat27dqlWrVqacOGDYqIiJAkLVmyRPfee69+//13hYSE5KstaWlp8vX1VWpqqnx8fAqmg/+nyqivC3R+yNmBiTFF3QQAQCG7nvvvm0GxO/L35ZdfKiIiQp06dVJgYKDq1aund99915q+f/9+JSYmKioqyirz9fVVgwYNlJCQIElKSEiQn5+fFfwkKSoqSi4uLlq3bl2uyz537pzS0tKcfgAAAG4mxS787du3T1OmTFH16tW1dOlSPfbYYxo0aJBmzZolSUpMTJQkBQUFOb0uKCjImpaYmKjAwECn6W5ubvL397fq5CQ+Pl6+vr7WT8WKFQuyawAAAEWu2IW/zMxM3XnnnXrhhRdUr1499evXT3379tXUqVOv+7Lj4uKUmppq/Rw+fPi6LxMAAKAwFbvwV758edWqVcuprGbNmjp06JAkKTg4WJKUlJTkVCcpKcmaFhwcrOTkZKfp6enpOnHihFUnJx4eHvLx8XH6AQAAuJkUu/DXuHFj7d6926lsz549qly5siQpNDRUwcHBWr58uTU9LS1N69atU2RkpCQpMjJSKSkp2rRpk1VnxYoVyszMVIMGDQqhFwAAAMWTW1E34FJPPfWUGjVqpBdeeEGdO3fW+vXrNX36dE2fPl2S5HA4NHjwYI0fP17Vq1dXaGioRo8erZCQELVv317S30cK27RpY50uvnDhggYOHKiuXbvm+05fAACAm1GxC3933XWXPvvsM8XFxen5559XaGioXn/9dXXr1s2qM2LECJ0+fVr9+vVTSkqKmjRpoiVLlsjT09OqM2fOHA0cOFCtWrWSi4uLOnTooDfffLMougQAAFBsFLvn/BUnPOfvxsdz/gDAfnjOX96K3TV/AAAAuH4IfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZS7MPfxIkT5XA4NHjwYKvs7NmzGjBggMqWLStvb2916NBBSUlJTq87dOiQYmJiVLJkSQUGBmr48OFKT08v5NYDAAAUL8U6/G3YsEHTpk3T7bff7lT+1FNP6auvvtLChQu1atUqHT16VA899JA1PSMjQzExMTp//rx+/PFHzZo1SzNnztSYMWMKuwsAAADFSrENf6dOnVK3bt307rvvqkyZMlZ5amqq3n//fb366qu6++67FR4erhkzZujHH3/U2rVrJUnffvutdu7cqQ8//FB169ZV27ZtNW7cOL3zzjs6f/58UXUJAACgyBXb8DdgwADFxMQoKirKqXzTpk26cOGCU3mNGjVUqVIlJSQkSJISEhJUp04dBQUFWXWio6OVlpamHTt25LrMc+fOKS0tzekHAADgZuJW1A3Iybx587R582Zt2LAh27TExES5u7vLz8/PqTwoKEiJiYlWnYuDX9b0rGm5iY+P19ixY6+x9QAAAMVXsTvyd/jwYT355JOaM2eOPD09C3XZcXFxSk1NtX4OHz5cqMsHAAC43opd+Nu0aZOSk5N15513ys3NTW5ublq1apXefPNNubm5KSgoSOfPn1dKSorT65KSkhQcHCxJCg4Oznb3b9bvWXVy4uHhIR8fH6cfAACAm0mxC3+tWrXStm3btHXrVusnIiJC3bp1s/5fokQJLV++3HrN7t27dejQIUVGRkqSIiMjtW3bNiUnJ1t1li1bJh8fH9WqVavQ+wQAAFBcFLtr/kqXLq3atWs7lZUqVUply5a1ynv37q0hQ4bI399fPj4+euKJJxQZGamGDRtKklq3bq1atWqpe/fumjRpkhITE/XMM89owIAB8vDwKPQ+AQAAFBfFLvzlx2uvvSYXFxd16NBB586dU3R0tCZPnmxNd3V11aJFi/TYY48pMjJSpUqVUmxsrJ5//vkibDUAAEDRcxhjTFE3orhKS0uTr6+vUlNTC/z6vyqjvi7Q+SFnBybGFHUTAACF7Hruv28Gxe6aPwAAAFw/hD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsJEb8jl/QH7diI/U4fE0AIDriSN/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARgh/AAAANkL4AwAAsJFiGf7i4+N11113qXTp0goMDFT79u21e/dupzpnz57VgAEDVLZsWXl7e6tDhw5KSkpyqnPo0CHFxMSoZMmSCgwM1PDhw5Wenl6YXQEAAChWimX4W7VqlQYMGKC1a9dq2bJlunDhglq3bq3Tp09bdZ566il99dVXWrhwoVatWqWjR4/qoYcesqZnZGQoJiZG58+f148//qhZs2Zp5syZGjNmTFF0CQAAoFhwGGNMUTfico4dO6bAwECtWrVKzZo1U2pqqgICAjR37lx17NhRkvTLL7+oZs2aSkhIUMOGDbV48WLdd999Onr0qIKCgiRJU6dO1ciRI3Xs2DG5u7tfdrlpaWny9fVVamqqfHx8CrRPVUZ9XaDzw83jwMSYom4CANzQruf++2ZQLI/8XSo1NVWS5O/vL0natGmTLly4oKioKKtOjRo1VKlSJSUkJEiSEhISVKdOHSv4SVJ0dLTS0tK0Y8eOHJdz7tw5paWlOf0AAADcTIp9+MvMzNTgwYPVuHFj1a5dW5KUmJgod3d3+fn5OdUNCgpSYmKiVefi4Jc1PWtaTuLj4+Xr62v9VKxYsYB7AwAAULSKffgbMGCAtm/frnnz5l33ZcXFxSk1NdX6OXz48HVfJgAAQGFyK+oG5GXgwIFatGiRVq9erVtuucUqDw4O1vnz55WSkuJ09C8pKUnBwcFWnfXr1zvNL+tu4Kw6l/Lw8JCHh0cB9wIAAKD4KJZH/owxGjhwoD777DOtWLFCoaGhTtPDw8NVokQJLV++3CrbvXu3Dh06pMjISElSZGSktm3bpuTkZKvOsmXL5OPjo1q1ahVORwAAAIqZYnnkb8CAAZo7d66++OILlS5d2rpGz9fXV15eXvL19VXv3r01ZMgQ+fv7y8fHR0888YQiIyPVsGFDSVLr1q1Vq1Ytde/eXZMmTVJiYqKeeeYZDRgwgKN7AADAtopl+JsyZYokqUWLFk7lM2bMUI8ePSRJr732mlxcXNShQwedO3dO0dHRmjx5slXX1dVVixYt0mOPPabIyEiVKlVKsbGxev755wurGwAAAMXODfGcv6LCc/5QFHjOHwBcG57zl7diec0fAAAArg/CHwAAgI0Uy2v+ADu7ES8J4FQ1ANw4OPIHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAG3Er6gYAuPFVGfV1UTfhih2YGFPUTQCAIsGRPwAAABsh/AEAANgI4Q8AAMBGCH8AAAA2QvgDAACwEcIfAACAjRD+AAAAbITwBwAAYCOEPwAAABsh/AEAANgIX+8GwJZuxK+kk/haOgDXjiN/AAAANkL4AwAAsBHCHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAbIfwBAADYCOEPAADARnjIMwDcQG7Eh1PzYGqgeOHIHwAAgI0Q/gAAAGyE8AcAAGAjhD8AAAAb4YYPAMB1dSPepHIj4sYa5BdH/gAAAGyE8AcAAGAjN334e+edd1SlShV5enqqQYMGWr9+fVE3CQAAoMjc1OFv/vz5GjJkiJ599llt3rxZd9xxh6Kjo5WcnFzUTQMAACgSN3X4e/XVV9W3b1/17NlTtWrV0tSpU1WyZEl98MEHRd00AACAInHT3u17/vx5bdq0SXFxcVaZi4uLoqKilJCQkONrzp07p3Pnzlm/p6amSpLS0tIKvH2Z584U+DwBAPZ1PfZVN6qssTDGFHFLiqebNvwdP35cGRkZCgoKcioPCgrSL7/8kuNr4uPjNXbs2GzlFStWvC5tBACgoPi+XtQtKH5OnjwpX1/fom5GsXPThr+rERcXpyFDhli/Z2Zm6sSJEypbtqwcDsdlX5+WlqaKFSvq8OHD8vHxuZ5NvekwdteG8bt6jN3VY+yuHmN39fIzdsYYnTx5UiEhIYXcuhvDTRv+ypUrJ1dXVyUlJTmVJyUlKTg4OMfXeHh4yMPDw6nMz8/vipft4+PDh/kqMXbXhvG7eozd1WPsrh5jd/UuN3Yc8cvdTXvDh7u7u8LDw7V8+XKrLDMzU8uXL1dkZGQRtgwAAKDo3LRH/iRpyJAhio2NVUREhOrXr6/XX39dp0+fVs+ePYu6aQAAAEXipg5/Xbp00bFjxzRmzBglJiaqbt26WrJkSbabQAqKh4eHnn322WynjnF5jN21YfyuHmN39Ri7q8fYXT3G7to5DPdBAwAA2MZNe80fAAAAsiP8AQAA2AjhDwAAwEYIfwAAADZC+AMAALARwl8Beuedd1SlShV5enqqQYMGWr9+fVE3qUjFx8frrrvuUunSpRUYGKj27dtr9+7dTnXOnj2rAQMGqGzZsvL29laHDh2yfSvLoUOHFBMTo5IlSyowMFDDhw9Xenp6YXalyE2cOFEOh0ODBw+2yhi73B05ckSPPvqoypYtKy8vL9WpU0cbN260phtjNGbMGJUvX15eXl6KiorS3r17neZx4sQJdevWTT4+PvLz81Pv3r116tSpwu5KocvIyNDo0aMVGhoqLy8vhYWFady4cbr4wRCM399Wr16t+++/XyEhIXI4HPr888+dphfUOP38889q2rSpPD09VbFiRU2aNOl6d+26y2vsLly4oJEjR6pOnToqVaqUQkJC9M9//lNHjx51moddx65AGBSIefPmGXd3d/PBBx+YHTt2mL59+xo/Pz+TlJRU1E0rMtHR0WbGjBlm+/btZuvWrebee+81lSpVMqdOnbLq/Otf/zIVK1Y0y5cvNxs3bjQNGzY0jRo1sqanp6eb2rVrm6ioKLNlyxbzzTffmHLlypm4uLii6FKRWL9+valSpYq5/fbbzZNPPmmVM3Y5O3HihKlcubLp0aOHWbdundm3b59ZunSp+fXXX606EydONL6+vubzzz83P/30k2nXrp0JDQ01f/31l1WnTZs25o477jBr1641a9asMdWqVTMPP/xwUXSpUE2YMMGULVvWLFq0yOzfv98sXLjQeHt7mzfeeMOqw/j97ZtvvjFPP/20+fTTT40k89lnnzlNL4hxSk1NNUFBQaZbt25m+/bt5qOPPjJeXl5m2rRphdXN6yKvsUtJSTFRUVFm/vz55pdffjEJCQmmfv36Jjw83Gkedh27gkD4KyD169c3AwYMsH7PyMgwISEhJj4+vghbVbwkJycbSWbVqlXGmL8/4CVKlDALFy606uzatctIMgkJCcaYvzcQLi4uJjEx0aozZcoU4+PjY86dO1e4HSgCJ0+eNNWrVzfLli0zzZs3t8IfY5e7kSNHmiZNmuQ6PTMz0wQHB5uXXnrJKktJSTEeHh7mo48+MsYYs3PnTiPJbNiwwaqzePFi43A4zJEjR65f44uBmJgY06tXL6eyhx56yHTr1s0Yw/jl5tIAU1DjNHnyZFOmTBmnz+zIkSPNrbfeep17VHhyCs6XWr9+vZFkDh48aIxh7K4Vp30LwPnz57Vp0yZFRUVZZS4uLoqKilJCQkIRtqx4SU1NlST5+/tLkjZt2qQLFy44jVuNGjVUqVIla9wSEhJUp04dp29liY6OVlpamnbs2FGIrS8aAwYMUExMjNMYSYxdXr788ktFRESoU6dOCgwMVL169fTuu+9a0/fv36/ExESnsfP19VWDBg2cxs7Pz08RERFWnaioKLm4uGjdunWF15ki0KhRIy1fvlx79uyRJP3000/64Ycf1LZtW0mMX34V1DglJCSoWbNmcnd3t+pER0dr9+7d+vPPPwupN0UvNTVVDodDfn5+khi7a3VTf71bYTl+/LgyMjKyfW1cUFCQfvnllyJqVfGSmZmpwYMHq3Hjxqpdu7YkKTExUe7u7taHOUtQUJASExOtOjmNa9a0m9m8efO0efNmbdiwIds0xi53+/bt05QpUzRkyBD9+9//1oYNGzRo0CC5u7srNjbW6ntOY3Px2AUGBjpNd3Nzk7+//009dpI0atQopaWlqUaNGnJ1dVVGRoYmTJigbt26SRLjl08FNU6JiYkKDQ3NNo+saWXKlLku7S9Ozp49q5EjR+rhhx+Wj4+PJMbuWhH+UCgGDBig7du364cffijqptwQDh8+rCeffFLLli2Tp6dnUTfnhpKZmamIiAi98MILkqR69epp+/btmjp1qmJjY4u4dcXfggULNGfOHM2dO1e33Xabtm7dqsGDByskJITxQ6G7cOGCOnfuLGOMpkyZUtTNuWlw2rcAlCtXTq6urtnutExKSlJwcHARtar4GDhwoBYtWqSVK1fqlltuscqDg4N1/vx5paSkONW/eNyCg4NzHNesaTerTZs2KTk5WXfeeafc3Nzk5uamVatW6c0335Sbm5uCgoIYu1yUL19etWrVciqrWbOmDh06JOn/9z2vz2twcLCSk5Odpqenp+vEiRM39dhJ0vDhwzVq1Ch17dpVderUUffu3fXUU08pPj5eEuOXXwU1Tnb9HEv/P/gdPHhQy5Yts476SYzdtSL8FQB3d3eFh4dr+fLlVllmZqaWL1+uyMjIImxZ0TLGaODAgfrss8+0YsWKbIffw8PDVaJECadx2717tw4dOmSNW2RkpLZt2+b0Ic/aCFy6g7+ZtGrVStu2bdPWrVutn4iICHXr1s36P2OXs8aNG2d7pNCePXtUuXJlSVJoaKiCg4Odxi4tLU3r1q1zGruUlBRt2rTJqrNixQplZmaqQYMGhdCLonPmzBm5uDjvGlxdXZWZmSmJ8cuvghqnyMhIrV69WhcuXLDqLFu2TLfeeutNfdoyK/jt3btX3333ncqWLes0nbG7RkV9x8nNYt68ecbDw8PMnDnT7Ny50/Tr18/4+fk53WlpN4899pjx9fU133//vfnf//5n/Zw5c8aq869//ctUqlTJrFixwmzcuNFERkaayMhIa3rW40pat25ttm7dapYsWWICAgJu+seV5OTiu32NYexys379euPm5mYmTJhg9u7da+bMmWNKlixpPvzwQ6vOxIkTjZ+fn/niiy/Mzz//bB544IEcH8FRr149s27dOvPDDz+Y6tWr33SPKslJbGysqVChgvWol08//dSUK1fOjBgxwqrD+P3t5MmTZsuWLWbLli1Gknn11VfNli1brDtSC2KcUlJSTFBQkOnevbvZvn27mTdvnilZsuQN/7iSvMbu/Pnzpl27duaWW24xW7duddp/XHznrl3HriAQ/grQW2+9ZSpVqmTc3d1N/fr1zdq1a4u6SUVKUo4/M2bMsOr89ddf5vHHHzdlypQxJUuWNA8++KD53//+5zSfAwcOmLZt2xovLy9Trlw5M3ToUHPhwoVC7k3RuzT8MXa5++qrr0zt2rWNh4eHqVGjhpk+fbrT9MzMTDN69GgTFBRkPDw8TKtWrczu3bud6vzxxx/m4YcfNt7e3sbHx8f07NnTnDx5sjC7USTS0tLMk08+aSpVqmQ8PT1N1apVzdNPP+2002X8/rZy5coct3GxsbHGmIIbp59++sk0adLEeHh4mAoVKpiJEycWVhevm7zGbv/+/bnuP1auXGnNw65jVxAcxlz02HYAAADc1LjmDwAAwEYIfwAAADZC+AMAALARwh8AAICNEP4AAABshPAHAABgI4Q/AAAAGyH8AQAA2AjhDwAAwEYIfwAAADZC+AMAALCR/wcSKslHDwDjZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(X):\n",
    "    len_ = [len(_) for _ in X]\n",
    "    plt.hist(len_)\n",
    "    plt.title('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.show()\n",
    "    \n",
    "plot_hist(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [len(word) for word in X_train]\n",
    "\n",
    "less = []\n",
    "for word in length:\n",
    "    if word <= 400:\n",
    "        less.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(less)/len(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably see that 90 to 95% of your sentences have less than 300 words. And very few have more than 1000.\n",
    "\n",
    "However, as you didn't use `maxlen` in your padding above, your input tensor has a dimension equal to the length of the sentence that has the maximum number of words.\n",
    "\n",
    "Now, let's look at how this affects the padding: \n",
    "\n",
    "\n",
    "<img src=\"tensor_size.png\" alt='Word2Vec' width=\"700px\" />\n",
    "\n",
    "Because of a few of very long sentences, one dimension of your tensor is equal to around 1000. However, most of the sentences with ~200 words have just padded values that are useless.\n",
    "\n",
    "So your tensor is mostly useless information, which still adds time to the training process.\n",
    "\n",
    "But what if you pad the data to a maximum length (`maxlen`) of say 200 (words)?\n",
    "- First, that would increase the convergence and you would not need to stare at your screen while waiting for the algorithm to converge\n",
    "- But in essence, do you really lose that much information? Do you think that you often need more than 200 words (up to 1000) to tell whether or not a sentence is positive of negative?\n",
    "\n",
    "❓ **Question** ❓ For all these reasons, re-do your padding using the `maxlen` keyword and retrain the model!  See how much faster it is now - without hurting the performance ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen=400)\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 19s 142ms/step - loss: 0.2352 - accuracy: 0.9194 - val_loss: 0.4810 - val_accuracy: 0.7867\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.1159 - accuracy: 0.9589 - val_loss: 0.6141 - val_accuracy: 0.7707\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 14s 129ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.6497 - val_accuracy: 0.7760\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 14s 131ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.7287 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7870 - val_accuracy: 0.8093\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience = 4, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad,\n",
    "                    y_train, \n",
    "                    batch_size=16, \n",
    "                    validation_split=0.3,\n",
    "                    epochs = 20,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(X_test_pad, y_test, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7656000256538391"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
